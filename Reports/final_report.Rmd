---
title: "Trust the pRocess: NBA Award Predictions"
subtitle: "STAT 385 SP2019 - Team Hurst"
abstract: |
          | This project will involve looking at 30 years of individual NBA player statistics. We will run an analysis using this historical data to develop a regression function for each individual regular season award in the NBA (Most Valuable Player, Defensive Player of the Year, Rookie of the Year, and Sixth Man of the Year). We will use this to determine every player's likelihood of winning each award. We will visualize these results using radar charts in a Shiny app.
          |
          
date: "May 9th, 2019"
author:
  - Ajay Dugar (dugar3)
  - Eric Qian (ewqian2)
  - Joshua Immanuel (joshuai2)
  - Bhanuchandra Kappala (kappala2)
output: 
  bookdown::pdf_document2
bibliography: bibliography.bib
nocite: '@*'
---

```{r set-options, include = FALSE}
# Sets default chunk options
knitr::opts_chunk$set(
  # Figures/Images will be centered
  fig.align = "center", 
  # Code will not be displayed unless `echo = TRUE` is set for a chunk
  echo = FALSE,
  # Messages are suppressed
  message = FALSE,
  # Warnings are suppressed
  warning = FALSE
)
```

```{r install-and-load-packages, include = FALSE, eval=FALSE}
# All packages needed should be loaded in this chunk
pkg_list = c('knitr', 'kableExtra', 'magrittr', 'bookdown')

# Determine what packages are NOT installed already.
to_install_pkgs = pkg_list[!(pkg_list %in% installed.packages()[,"Package"])]

# Install the missing packages
if(length(to_install_pkgs)) {
  install.packages(to_install_pkgs, repos = "https://cloud.r-project.org")
}

# Load all packages
sapply(pkg_list, require, character.only = TRUE)
```
-
<!-- Force a new page -->
\newpage

# Introduction

## Problem Statement

While fans and media pundits try to guess the winners of the major NBA awards (Most Valuable Player, Defensive Player of the Year, Rookie of the Year, and Sixth Man of the Year), the issue is that there's no real criteria or concrete way of predicting the winners of these awards. In this project, we seek to use historical data to predict these winners.

## Relevance
  
  Valuing player assets are important. Being able to accurately determine player value is one of the most fundamental skills in basketball front offices. Being able to do so accurately can be the difference between winning and losing. Many different subjects (statistitcs, differential equations, analytics) can be applied to these problems. With the success of Daryl Morey and Sam Hinkie, we see that these approaches have been successful in the NBA. Many interesting and unsolved issues in the NBA require statistical analysis, which is why we chose this project.
  
  Our shared passion of basketball and the NBA led us to this topic. This is a topic that some of us have talked about and  previous academic curiousity have led us to this topic. We wanted to know if we could use a variety of variables to accurately predict NBA Award winners.
  
## Description of the data

The data is a series of dataframes of regular and advanced statistics spanning from 1989 and 2019. The statistics are listed and explained in the Appendix. Our data will come from the NBA Reference website. It will be 30 years of individual player data. The long time period and amount of data for our data points will allow us for a greater degree of accuracy and precision in the evaluation of our model.


## Connection to the Course
  
We will be dealing with large datasets, validating data, and building statistical models. All of these skills form the foundations of statistical programming and we will apply what we have learned in our project.

# Related Work

## Previous Approaches

While not specifically related to this project, the application of sabermetrics has become a point of interest for many baseball teams. Likewise, we have began to see this same transition in basketball analytics. The long term view of teams that have embraced analytics has been very good: the Philadelphia 76ers and Houston Rockets are both top seeded teams that have a significant chance at being the Championship team. While we haven't seen rigorous academic analysis of predicting NBA awards, there have been some implementations done by various individuals. There are also award trackers that just use raw data - specifically VORP (Value over Replacement Player) and PER (Player Efficiency Rating) and the player with the highest value is predicted to win. While these ways of predicting awards works somewhat well, they tend to have problems undervaluing certain players (the inventor of PER notes that it is not an end all metric - it rewards inefficient shooting and doesn't sufficiently reward effective defense) so our idea will be unique.

## Originality

A lot of the statistics in use with modern publications are based on the research of one individual: Daryl Morey. We will derive our own variables and determine how impactful they are in determining wins using a regression  model. By doing so, we will establish other variables and metrics that may be better suited for different situations and will allow for better comparison of players across time periods and eras.

# Methods

First we use the ballr package [@ballr] to pull the statistical data from Basketball Reference website [@bball_ref]. Then we clean and combine the data using the concepts of "tidy data" [@tidyr]. We introduce dummy variables with respect to position (C, SG, SF, PF, PG).  

For the interactive interface, we have created a Shiny App. The user can choose both the year (between 1989 and 2019) and the award to be predicted. 

In order to visualize the data, we give radar plots of different attributes important for each of the awards. Next to this is the probability that that person would win the award.


To satisfy this section, provide detailed responses for the following:

- What packages will you use in your implementation?
  - Data transformation: tidyr, dplyr, ballr
  - Data visualization: plotly
  - Interactive Interface: shiny
  - Regression Analysis: leaps, glmnet, caret
  
- What code will the group need to write for the project?
  1. Code for importing the data
  2. Code for cleaning the pre-collected data and randomizing it
  3. Code to create the linear regression in obtaining the weights for each respective variables
  4. Code to create the toggle bar for the user interface input
  5. Code to create the interactive bar graph where it also displays the summary of the players
  
- Provide low-fidelity prototypes (e.g. _sketches_ on paper) in the **Appendix** of:
    - Visualisations
        - What kinds of graphs will you use?
        
        We will use a horizontal bar graph where the y-axis contains the player's names and the x-axis contains the predicted percentage scores. We will put a picture of the athlete on the right side of their respective bars. The user will be able to interact with the graph by toggling on the face of the athlete and a word cloud will appear. The word cloud will consist of the google trending discussions on the athlete.
        - Label axes, provide a title, and mention any interactivity.
    - Interface

- What have you done or learned so far for the project? 

We have learned that we need to gather the statistical player data and filter them so that the we have relevant data. We need to gather the variables and do regression to determine weights of each variables. We need to gather data on player discussion trends to project it in the graph. We also need to create a user interface where the we get the user input data and graph the predicted results as well as the player statistics.

We are primarily wanting to ensure that your project has met the criterion
of the data science pipeline. In essence, we want to see evidence that your
project has:

- Reading data into _R_ or accessing data via an API.
- Data transformations (e.g. Tidying ([`tidyr`](http://tidyr.tidyverse.org/)), Summarizing ([`dplyr`](http://dplyr.tidyverse.org/)), et cetera.)
- Data visualization (e.g. [`ggplot2`](http://ggplot2.tidyverse.org/),
  [`plotly`](https://plot.ly/ggplot2/), [`gganimate`](https://github.com/dgrtwo/gganimate))
- R functions either in external packages or included in a new _R_ package
- Interactive Interface (e.g. [`shiny`](https://shiny.rstudio.com/))
- Reproducibility

# Results



# Discussion

# Conclusion

Overall, the project was generally successful. We took historical data and 

The **Feasibility** section is meant to act as a way to reflect upon the proposal.
Generally speaking, there will be three weeks of heavy development time afforded
to the group. Building a detailed ecosystem or heavily scripting in a different
language will likely not lead your team to success. Hence, please provide
a project management overview of *who* on your team will be doing *what* and *when*
by answering:

- Is this project able to be completed before the end of the semester?

It should be - while the data set is large, outside of the resource requirement, it should not be overly difficult to implement this specific idea. We will need to familiarize ourself with the specific data used here - lots of unique compiled stats are used in basketball as opposed to the typical counting stats. 

- What steps must occur to complete the project before the end of the semester?

Accumulate the data in a timely manner - we must find what data we are going to use and apply our model to it. We plan to have 30 years worth of data so data cleaning/valdiation is an important and time consuming portion. We must also create specific derived variables that will more effectively illustrate the value of each player to their team for all the specific criteria. We must then model each of the awards - they will all have unique weights for each of the statistics.

- What is the work plan to accomplish the necessary tasks before the end of the
  semester?
  - Specify who is doing what and when.
  - Consider making a [Gantt chart](https://en.wikipedia.org/wiki/Gantt_chart)
    to highlight each stage of the project.
    
    Ajay - obtain data (primarily from BBallRef) and create derived variables
    Bhanu - build model and generate output (train model for each individual award)
    Joshua and Eric - build visualization components of the Shiny app
    Ajay and Bhanu - add sentiment analysis portion to visualizations (make a word cloud)

# Conclusion

If you can accurately predict NBA awards, there is significant money to be made
betting on winners of these awards. Additionally, by looking at this topic,
NBA teams can get a better idea of what a winning player looks like, and can
construct teams accordingly.

This project will involve looking at 30 years of individual NBA player statistics. 
We will develop a number of new advanced analytics and statistics to determine 
player efficient and value. Using these numbers, we will rank players and determine
who should win prominent NBA awards. We will visualize these results using bar graphs 
and sentiment analysis.

\newpage

# Appendix

## Variables

- player - name of the player
- pos - position
- age - age
- g - games played
- mp - minutes played
- per - player efficiency rating

$$
per = (1 / mp) * [3p + (2/3) * ast + (2 - factor * (ast_{team} / fg_{team})) * fg + (ft *0.5 * (1 + (1 - (ast_{team} / fg_{team}))
$$
$$
+ (2/3) * (ast_{team} / fg_{team}))) - vop * tov - vop * drb\% * (fga - fg) - vop * 0.44 * (0.44 + (0.56 * drb\%)) * (fta - ft) 
$$
$$
+ vop * (1 - drb\%) * (drb) + vop * drb\% * orb + vop * stl + vop * drb\% * blk - pf * ((ft_{league} / pf_{league}) - 0.44 * (fta_{league}/pf_{league}) * vop)]
$$

- tspercent - true shooting percent

$$
tspercent = \frac{pts}{2*(fga + (0.44*fta))}*100
$$
- x3par - 3 point attempt rate
- ows - offensive win shares
- dws - defensive win shares
- trbpercent - total rebound percentage
- astpercentage - assist percentage
- blkpercent - block percentage
- tovpercent - turnover percentage
- usgpercent - usage percentage
- ftr - free throw rate
- ws - win shares
- ws_48 - win shares per 48 minutes
- gs - games started 
- fg - field goals made
- fga - field goals attempted
- fgpercent - field goal percentage
- orb - offensive rebounds
- drb - defensive rebounds
- trb - total rebounds
- x3p - 3 pointers made
- x3pa - 3 pointers attempted
- x3ppercent - 3 point percentage
- x2p - 2 pointers made
- x2pa - 2 pointers attempted
- x2ppercent - 2 point percentage
- ast - assists
- stl - steals
- ft - free throws
- fta - free throw attempts
- ftpercent - free throw percentage
- blk - blocks
- tov - turnovers
- pf - personal fouls
- pts - points per game
- efgpercent - effective field goal percentage
- obpm - offensive box plus/minus
- dbpm - defensive box plus/minus
- bpm - total box plus/minus
- vorp - value over replacement player



to contain all of your _planning_ information.

- Provide the sketches of visualisations and the shiny application.
- Provide an overview on the desired functions.
    - What is a function's input? Output? How are functions related to each other.
    - For example, `read_data("hospital_data.csv")` must be called before `tidy_hospital()`, et cetera.
- Provide a sample of the data set you intend to use (~10 observations).

```{r}
example = read.csv("example.csv")
print(example)
```



If you used previous code chunks within the document, this information can
be dynamically retrieved and embedded.

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```

```{r hitters-data, eval=FALSE}
kable(
  head(mtcars, 20),
  format = "latex",
  caption = "This is an example of a table in the Appendix. Notice that it is way too big, and has way too much information. We use the $\\texttt{kableExtra}$ package to shrink it down, but even then, no one would actually read this table.",
  booktabs = TRUE
) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
```

```{r wage-data, eval=FALSE}
kable(
  head(mtcars, 20),
  format = "latex",
  caption = "This is another example of a ridiculous table. Notice that it is automatically numbered.",
  booktabs = TRUE
) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
```


## Formatting Notes


### `R` Code and `rmarkdown`

An important part of the report is communicating results in a well-formatted manner. This template document should help a lot with that task. Some thoughts on using `R` and `rmarkdown`:

- Chunks are set to not echo by default in this document.
- Consider naming your chunks. This will be necessary for referencing chunks 
  that create tables or figures.
- One chunk per table or figure!
- Tables should be created using `knitr::kable()`.
- Consider using `kableExtra()` for better presentation of tables. (Examples in this document.)
- Caption all figures and tables. (Examples in this document.)
- Use the `img/` sub-directory for any external images.
- Use the `data/` sub-directory for any external data.

### LaTeX

While you will not directly work with LaTeX, you may wish to have some details
on working with TeX can be found in 
[this guide by UIUC Mathematics Professor A.J. Hildebrand ](https://faculty.math.illinois.edu/~hildebr/tex/latex-start.html).

With `rmarkdown`, LaTeX can be used inline, like this, $a ^ 2 + b ^ 2 = c ^ 2$,
or using display mode,

$$
\mathbb{E}_{X, Y} \left[ (Y - f(X)) ^ 2 \right] = \mathbb{E}_{X} \mathbb{E}_{Y \mid X} \left[ ( Y - f(X) ) ^ 2 \mid X = x \right]
$$

You **are** required to use BibTeX for references. With BibTeX, we could 
reference the `rmarkdown` paper or the tidy data paper.
 Some details can be found in the 
[`bookdown` book](https://bookdown.org/yihui/bookdown/citations.html). Also,
hint, [Google Scholar](https://scholar.google.com/) makes obtaining BibTeX 
reference extremely easy. For more details, see the next section...

<!-- Force a new page for references -->
\newpage

# References



